#Author : Rohan M. Nanaware
#Date C.: 12th Jul 2017
#Date M.: 12th Jul 2017
#       : 14th Jul 2017 : Run basic linear model to check knowledge level and base accuracy
#       : 27th Jul 2017 : Ran XGBoost on NA imputed dataset. 
                          # Next steps
                            #  Variable importance plots, use MAPE instead of RMSE, 
                            #  learn how to interpret RMSE - thresholds etc, 
                            #  k-fold validation, hypertuning, feature enginnering
#       : 02nd Aug 2017 : Variable importance plots - observed marginal improvement in model o/p, 
#                         model performace did not improve by nround and max_depth change
#Purpose: Predict sales prices and practice feature engineering, RFs, and gradient boosting

{
  library(data.table)
  library(Matrix)
  library(rpart)
  library(xgboost)
  library(readr)
  library(stringr)
  library(caret)
  library(car)
  library(data.table)
  library(randomForest)
  library(ROCR)
  library(dplyr)
  # Create the mode function.
  getmode <- function(v) {
    uniqv <- unique(v)
    uniqv[which.max(tabulate(match(v, uniqv)))]
  }
  
}#01. Load required packages
{
  setwd("E:/Delivery/1 Active/Kaggle/House Prices Advanced Regression Technique") 
}#02. Set working directory
{
  train    <- read.csv("train.csv", header = T, stringsAsFactors = F)
  test     <- read.csv("test.csv", header = T, stringsAsFactors = F)
  HP.TOTAL <- rbind(train[,!(colnames(train) == "SalePrice")],test)
}#03. Load data
{
  nrow(HP.TOTAL)
  sapply(HP.TOTAL, function(x) sum(is.na(x))) / nrow(HP.TOTAL)
  View(head(HP.TOTAL))
  sapply(HP.TOTAL, function(x) length(unique(x)))
}#04. Understand data
{
  #str(HP.TOTAL)
  #sapply(HP.TOTAL, function(x) sum(is.na(x)))/length(HP.TOTAL$Id)*100
  #Imputation
    #Imputation techniques - overall median, selective mean/median, prediction, KNN
  #Outlier treatment
  
  #Order of appearance in data
  #Id         - House ID, filter out
  HP.TOTAL.IMPUTE <- HP.TOTAL[, !(colnames(HP.TOTAL) == 'Id')]
  
  #MSSubClass - Type of dwelling - Categorical - Convert to factor, Check distribution and clubbing
  #barplot(prop.table(table(HP.TOTAL.IMPUTE$MSSubClass)))
  HP.TOTAL.IMPUTE$MSSubClass <- as.factor(HP.TOTAL.IMPUTE$MSSubClass)
  unique(HP.TOTAL.IMPUTE$MSSubClass)
  
  #MSZoning   - Zoning classification - Categorical - Convert to factor, Level reduction for Residential, imputation
  table(HP.TOTAL.IMPUTE$MSZoning)
  HP.TOTAL.IMPUTE$MSZoning[is.na(HP.TOTAL.IMPUTE$MSZoning)] <- getmode(HP.TOTAL.IMPUTE$MSZoning[!is.na(HP.TOTAL.IMPUTE$MSZoning)])

  #LotFrontage- Linear feet of street - Numeric - Impute
  #sapply(HP.TOTAL.IMPUTE, function(x) sum(is.na(x)))
  #summary(HP.TOTAL.IMPUTE$LotFrontage)
  #Performing imputation by taking median values, for future improvements impute by prediction or use KNN
  HP.TOTAL.IMPUTE$LotFrontage[is.na(HP.TOTAL.IMPUTE$LotFrontage)] <- median(HP.TOTAL.IMPUTE$LotFrontage[!is.na(HP.TOTAL.IMPUTE$LotFrontage)])
  
  #LotArea    - Lot size - Numeric - Outlier
  #Street     - Type of road access - Check distribution
  #Alley      - Type of alley access - Categorical - Define flag for NA, Check dist.
  HP.TOTAL.IMPUTE$Alley[is.na(HP.TOTAL.IMPUTE$Alley)] <- 'No alley access'
  
  #LotShape   - General shape of property - Categorical - Distribution and price variation
  #plot(x = train$LotShape,y = train$SalePrice, xlab = "Sale price", ylab = "Lot shape")
  
  #LandContour- Flatness of the property - Categorical - Check distribution
  #Utilities  - Type of utilities available - Categorical - Check distribution - Need to impute
  table(HP.TOTAL.IMPUTE$Utilities)
  
  #LotConfig  - Lot configuration - Categorical - Check distribution
  #LandSlope  - Slope of property - Categorical
  #Neighborhood-Physical locations - Categorical - Check distribution, reduce level
  #Condition1 - Proximity to various conditions - Cat - Check dist, reduce level
  #Condition2 - Check dependency on comndition 1
  #BldgType   - Type of dwelling - Cat - Check distribution and reduce level
  #HouseStyle - Style of dwelling - Cat - Check if a new feature can be define using house style and building type
  #OverallQual- Rates the overall material - Cat - Convert to factor - Check dist
  #OverallCond- Rates the overall condition - Cat - Convert to factor
  #YearBuilt  - Original construction - Date - Check trend of price with year
  #YearRemodAdd-Remodel date (same as construction date if no remodelling) - Date - Check if the recency of remodelling affects the price
  #RoofStyle  - Type of roof - Cat - Check dist.
  #RoofMatl   - Roof material - Cat - Check dist., Define new using Roofmaterial and Style
  
  #Exterior1st- Exterior covering - Cat - Check dist. and impute NAs
  HP.TOTAL.IMPUTE$Exterior1st[is.na(HP.TOTAL.IMPUTE$Exterior1st)] <- getmode(HP.TOTAL.IMPUTE$Exterior1st)
  
  #Exterior2nd- Exterior covering - Cat - Check dist. and impute NAs
  HP.TOTAL.IMPUTE$Exterior2nd[is.na(HP.TOTAL.IMPUTE$Exterior2nd)] <- getmode(HP.TOTAL.IMPUTE$Exterior2nd)
  
  #MasVnrType - Masonry veneer type - Cat - Check dist. and impute NAs
  #table(HP.TOTAL.IMPUTE$MasVnrType)
  HP.TOTAL.IMPUTE$MasVnrType[is.na(HP.TOTAL.IMPUTE$MasVnrType)] <- getmode(HP.TOTAL.IMPUTE$MasVnrType)
  
  #MasVnrArea - Masonry veneer area - Cat - Check dist. and impute NAs
  HP.TOTAL.IMPUTE$MasVnrArea[is.na(HP.TOTAL.IMPUTE$MasVnrArea)] <- median(HP.TOTAL.IMPUTE$MasVnrArea, na.rm = T)
  
  #ExterQual  - Quality of material on exterior - Cat - Check distribution
  #ExterCond  - Evaluates the present condition of marterial - Cat - Check dist., define new feature with ExterQual
  #Foundation - Type of foundation - Cat - Check distribution
  #BsmtQual   - Evaluates the height of the basement - Cat - Check distribution, impute NAs
  HP.TOTAL.IMPUTE$BsmtQual[is.na(HP.TOTAL.IMPUTE$BsmtQual)] <- "No Basement"
  
  #BsmtCond   - Evaluates the general condition of basement - Cat - Check dist,define new feature with BsmtQual
  HP.TOTAL.IMPUTE$BsmtCond[is.na(HP.TOTAL.IMPUTE$BsmtCond)] <- "No Basement"
  
  #BsmtExposure-Refers to walkout or garden level walls - Cat - Check distribution, impute NAs
  HP.TOTAL.IMPUTE$BsmtExposure[is.na(HP.TOTAL.IMPUTE$BsmtExposure)] <- "No Basement"
  
  #BsmtFinType1-Rating of basement finished area - Cat - Check dist., impute NAs
  HP.TOTAL.IMPUTE$BsmtFinType1[is.na(HP.TOTAL.IMPUTE$BsmtFinType1)] <- "No Basement"
  
  #BsmtFinSF1 - Type 1 finished square feet - Num - Outlier, NA imputation
  BSMTSF1_TYPE <- aggregate(HP.TOTAL.IMPUTE$BsmtFinSF1, list(HP.TOTAL.IMPUTE$BsmtFinType1), FUN = "mean")
  BSMTSF1_TYPE$x[BSMTSF1_TYPE$Group.1 == "No Basement"] = 0
  HP.TOTAL.IMPUTE$BsmtFinSF1[is.na(HP.TOTAL.IMPUTE$BsmtFinSF1)] <- BSMTSF1_TYPE$x[BSMTSF1_TYPE$Group.1 == HP.TOTAL.IMPUTE$BsmtFinType1[is.na(HP.TOTAL.IMPUTE$BsmtFinSF1)]]
  
  #BsmtFinType2-Rating of basement finished area - Cat
  HP.TOTAL.IMPUTE$BsmtFinType2[is.na(HP.TOTAL.IMPUTE$BsmtFinType2)] <- "No Basement"
  
  #BsmtFinSF2 - Type 2 finished square feet - Num - Check box plot results and impute
  unique(HP.TOTAL.IMPUTE$BsmtFinType2[is.na(HP.TOTAL.IMPUTE$BsmtFinSF2)])
  HP.TOTAL.IMPUTE$BsmtFinSF2[is.na(HP.TOTAL.IMPUTE$BsmtFinSF2)] <- 0
  
  #BsmtUnfSF  - Unfinished square feet - Num - Impute NAs
  unique(HP.TOTAL.IMPUTE$BsmtFinType2[is.na(HP.TOTAL.IMPUTE$BsmtUnfSF)])
  HP.TOTAL.IMPUTE$BsmtUnfSF[is.na(HP.TOTAL.IMPUTE$BsmtUnfSF)] <- 0
  
  #TotalBsmtSF- Total square feet - Num - Impute NAs
  HP.TOTAL.IMPUTE$TotalBsmtSF[is.na(HP.TOTAL.IMPUTE$TotalBsmtSF)] <- 0
  #Heating    - Type of heating - Cat - Check dist.
  #HeatingQC  - Heating quality - Cat - Check dist., define new features
  #CentralAir - Central air conditioning - Cat
  #Electrical - Electrical system - Cat
  table(HP.TOTAL.IMPUTE$Electrical)
  HP.TOTAL.IMPUTE$Electrical[is.na(HP.TOTAL.IMPUTE$Electrical)] <- getmode(HP.TOTAL.IMPUTE$Electrical)
  
  #X1stFlrSF  - First Floor square feet - Numeric, check dist., corelation
  #X2ndFlrSF  - Second floor square feet - Numeric, chekc dist., corelation
  #LowQualFinSF-Low quality finished square feet - Numeric, check dist., corelation
  #GrLivArea  - Above grade (ground) living area - Numeric, check dist.
  #BsmtFullBath-Basement full bathrooms - Numeric, check dist., imputation
  table(HP.TOTAL.IMPUTE$BsmtFullBath)
  HP.TOTAL.IMPUTE$BsmtFullBath[is.na(HP.TOTAL.IMPUTE$BsmtFullBath)] <- getmode(HP.TOTAL.IMPUTE$BsmtFullBath)
  
  #BsmtHalfBath-Basement half bathrooms - Numeric, check dist., imputation
  HP.TOTAL.IMPUTE$BsmtHalfBath[is.na(HP.TOTAL.IMPUTE$BsmtHalfBath)] <- getmode(HP.TOTAL.IMPUTE$BsmtHalfBath)
  
  #FullBath   - Full bathrooms above grade - Numeric, check dist
  #HalfBath   - Half baths above grade - Numeric, check dist
  #Bedroom    - Bedrooms above grade
  #Kitchen    - Kitchens above grade, numeric
  #KitchenQual- Kitchen quality, character, impute
  table(HP.TOTAL.IMPUTE$KitchenQual)
  HP.TOTAL.IMPUTE$KitchenQual[is.na(HP.TOTAL.IMPUTE$KitchenQual)] <- getmode(HP.TOTAL.IMPUTE$KitchenQual)
  
  #TotRmsAbvGrd-Numeric, check dist.
  #Functional - Home functionality, character
  table(HP.TOTAL.IMPUTE$Functional)
  HP.TOTAL.IMPUTE$Functional[is.na(HP.TOTAL.IMPUTE$Functional)] <- getmode(HP.TOTAL.IMPUTE$Functional)
  
  #Fireplaces - Number of fireplaces, numeric, check distribution
  #FireplaceQu- Fireplace quality, character, combine with Fireplaces and reduce levels, replace NA	with "No Fireplace"
  HP.TOTAL.IMPUTE$FireplaceQu[is.na(HP.TOTAL.IMPUTE$FireplaceQu)] <- "No Fireplace"
  
  #GarageType - Garage location, character, relpace NAs with "No Garage"
  HP.TOTAL.IMPUTE$GarageType[is.na(HP.TOTAL.IMPUTE$GarageType)] <- "No Garage"
  
  #GarageYrBlt- Year garage was built, numeric, substract from current year? year of sale?
  summary(HP.TOTAL.IMPUTE$GarageYrBlt)
  HP.TOTAL.IMPUTE$GarageYrBlt[is.na(HP.TOTAL.IMPUTE$GarageYrBlt)] <- median(HP.TOTAL.IMPUTE$GarageYrBlt, na.rm = T)
  
  #GarageFinish-Interior finish, character, replace NAs with "No Garage"
  HP.TOTAL.IMPUTE$GarageFinish[is.na(HP.TOTAL.IMPUTE$GarageFinish)] <- "No Garage"
  
  #GarageCars - Car capacity, numeric, impute NA with median
  summary(HP.TOTAL.IMPUTE$GarageCars)
  HP.TOTAL.IMPUTE$GarageCars[is.na(HP.TOTAL.IMPUTE$GarageCars)] <- 0
  
  #GarageArea - Size of garage, check dependency with GarageCars
  table(HP.TOTAL.IMPUTE$GarageArea)
  table(HP.TOTAL.IMPUTE$GarageArea[HP.TOTAL.IMPUTE$GarageFinish == "No Garage"])
  HP.TOTAL.IMPUTE$GarageArea[is.na(HP.TOTAL.IMPUTE$GarageArea)] <- 0
  
  #GarageQual - character, replace NAs with No garage
  HP.TOTAL.IMPUTE$GarageQual[is.na(HP.TOTAL.IMPUTE$GarageQual)] <- "No Garage"
  
  #GarageCond - character, replace NAs with No garage, combine with GarageQual
  HP.TOTAL.IMPUTE$GarageCond[is.na(HP.TOTAL.IMPUTE$GarageCond)] <- "No Garage"
  
  #PavedDrive - Paved driveway, character
  #WoodDeckSF - numeric, outlier treatment, check dist.
  #OpenPorchSF- numeric, outloer treatment, check dist.
  #EnclosedPorch-numeric, outlier tratment, check dist.
  #3SsnPorch
  #ScreenPorch
  #PoolArea
  #PoolQC     - Replace NAs with "No Pool"
  HP.TOTAL.IMPUTE$PoolQC[is.na(HP.TOTAL.IMPUTE$PoolQC)] <- "No Pool"
  
  #Fence      - Replca NAs with "No Fence"
  HP.TOTAL.IMPUTE$Fence[is.na(HP.TOTAL.IMPUTE$Fence)] <- "No Fence"
  
  #MiscFeature- Replca NAs with "None"
  HP.TOTAL.IMPUTE$MiscFeature[is.na(HP.TOTAL.IMPUTE$MiscFeature)] <- "None"
  
  #MiscVal    - outlier treatment
  #MoSold
  #YrSold     - use to calculate the age/recency of renovation of the house/garage
  #SaleType   - Type of payment 
  table(HP.TOTAL.IMPUTE$SaleType)
  HP.TOTAL.IMPUTE$SaleType[is.na(HP.TOTAL.IMPUTE$SaleType)] <- getmode(HP.TOTAL.IMPUTE$SaleType)
  
}#05. Impute NAs
{
  
  #http://www.statmethods.net/stats/regression.html
  str(HP.TOTAL)
  rpart_1 <- rpart(SalePrice ~ ., data = train[, !(colnames(train) %in% c("Id"))], method = "anova")
  summary(rpart_1)
  View(data.frame(rpart_1$variable.importance))
  predictions <- predict(rpart_1, test[, !(colnames(test) %in% c("Id"))])
  #kaggle blind submission - 
  RESULTS <- cbind(test$Id, predictions)
  colnames(RESULTS) <- c("Id","SalePrice")
  write.csv(RESULTS, "170714_HP_ITER1.csv", row.names = F)
  #Rank - 1676/1880 Score - 0.24474
  
}#06. Modelling technique - rpart
{
  #Run module - 01,02,03,05
  #Convert all categorical to factor
  str(HP.TOTAL.IMPUTE)
  
  HP.TOTAL.IMPUTE[, (colnames(HP.TOTAL.IMPUTE) %in% c("OverallQual","OverallCond") |
                       sapply(HP.TOTAL.IMPUTE, function(x) class(x)) == "character")] <-
  data.frame(sapply(HP.TOTAL.IMPUTE[, (colnames(HP.TOTAL.IMPUTE) %in% c("OverallQual","OverallCond") |
                                            sapply(HP.TOTAL.IMPUTE, function(x) class(x)) == "character")
                                       ],
                       function(x) as.factor(x)))
  #Features to be encoded
  FEATURES_OHE <- c( "MSSubClass",    "MSZoning",      "Street",      
                     "Alley",         "LotShape",      "LandContour",  
                     "Utilities",     "LotConfig",     "LandSlope",    
                     "Neighborhood",  "Condition1",    "Condition2",   
                     "BldgType",      "HouseStyle",    "OverallQual",  
                     "OverallCond",   "RoofStyle",     "RoofMatl",     
                     "Exterior1st",   "Exterior2nd",   "MasVnrType",   
                     "ExterQual",     "ExterCond",     "Foundation",   
                     "BsmtQual",      "BsmtCond",      "BsmtExposure", 
                     "BsmtFinType1",  "BsmtFinType2",  "Heating",      
                     "HeatingQC",     "CentralAir",    "Electrical",   
                     "KitchenQual",   "Functional",    "FireplaceQu",  
                     "GarageType",    "GarageFinish",  "GarageQual",   
                     "GarageCond",    "PavedDrive",    "PoolQC",       
                     "Fence",         "MiscFeature",   "SaleType",     
                     "SaleCondition")
  DUMMIES <- dummyVars(~  MSSubClass+    MSZoning+      Street+      
                        Alley+         LotShape+      LandContour+  
                        Utilities+     LotConfig+     LandSlope+    
                        Neighborhood+  Condition1+    Condition2+   
                        BldgType+      HouseStyle+    OverallQual+  
                        OverallCond+   RoofStyle+     RoofMatl+     
                        Exterior1st+   Exterior2nd+   MasVnrType+   
                        ExterQual+     ExterCond+     Foundation+   
                        BsmtQual+      BsmtCond+      BsmtExposure+ 
                        BsmtFinType1+  BsmtFinType2+  Heating+      
                        HeatingQC+     CentralAir+    Electrical+   
                        KitchenQual+   Functional+    FireplaceQu+  
                        GarageType+    GarageFinish+  GarageQual+   
                        GarageCond+    PavedDrive+    PoolQC+       
                        Fence+         MiscFeature+   SaleType+     
                        SaleCondition,
                       data = HP.TOTAL.IMPUTE)
  HP.TOTAL.IMPUTE.OHE <- data.frame(predict(DUMMIES, newdata = HP.TOTAL.IMPUTE))
  HP.TOTAL.IMPUTE.ENC <- data.frame(cbind(HP.TOTAL.IMPUTE[, !(colnames(HP.TOTAL.IMPUTE) %in% FEATURES_OHE)], 
                                          HP.TOTAL.IMPUTE.OHE))
  {
    HP.TOTAL.IMPUTE.ENC.TRAIN <- data.frame(cbind(HP.TOTAL.IMPUTE.ENC[1:nrow(train),],  train$SalePrice)) 
    colnames(HP.TOTAL.IMPUTE.ENC.TRAIN)[length(colnames(HP.TOTAL.IMPUTE.ENC.TRAIN))] <- "SalePrice"
    HP.TOTAL.IMPUTE.ENC.TEST  <- data.frame(HP.TOTAL.IMPUTE.ENC[-(1:nrow(train)),])
  }#Split into train and test data
  
  #Split train set into 70:30 for validation
  #Run XGBoost
  set.seed(1007)
  HP.TOTAL.IMPUTE.ENC.TRAIN.7 <- HP.TOTAL.IMPUTE.ENC.TRAIN[1:(0.7*nrow(HP.TOTAL.IMPUTE.ENC.TRAIN)),]
  HP.TOTAL.IMPUTE.ENC.TRAIN.3 <- HP.TOTAL.IMPUTE.ENC.TRAIN[-(1:(0.7*nrow(HP.TOTAL.IMPUTE.ENC.TRAIN))),]
  XGB_1 <- xgboost(data = data.matrix(HP.TOTAL.IMPUTE.ENC.TRAIN.7[,!(colnames(HP.TOTAL.IMPUTE.ENC.TRAIN.7) == "SalePrice")]),
                   label = HP.TOTAL.IMPUTE.ENC.TRAIN.7$SalePrice,
                   eta = 0.01,
                   max_depth = 5,
                   nround = 2000,
                   seed = 1007,
                   objective = "reg:linear",
                   nthread = 3,
                   verbose = F)
  #Predict prices on the test data
  PREDICTIONS <- predict(XGB_1, data.matrix(HP.TOTAL.IMPUTE.ENC.TRAIN.3[,!(colnames(HP.TOTAL.IMPUTE.ENC.TRAIN.3) == "SalePrice")]))
  RMSE        <- sqrt(mean((PREDICTIONS - HP.TOTAL.IMPUTE.ENC.TRAIN.3$SalePrice)^2))
  #Kaggle submission - 
  PREDICTIONS <- predict(XGB_1, data.matrix(HP.TOTAL.IMPUTE.ENC.TEST))
  submission  <- cbind(test$Id, PREDICTIONS)
  colnames(submission)   <- c("Id", "SalePrice")
  write.csv(submission, "170727_HP_ITER2..csv", row.names = F)  
  #Rank - 1127 of 1764, score - 0.14487
  #Next steps - Use MAPE instead of RMSE, learn how to interpret RMSE - thresholds etc, k-fold validation, hypertuning, feature enginnering
  
  #Use MAPE instead of RMSE
  PREDICTIONS <- predict(XGB_1, data.matrix(HP.TOTAL.IMPUTE.ENC.TRAIN.3[,!(colnames(HP.TOTAL.IMPUTE.ENC.TRAIN.3) == "SalePrice")]))
  MAPE        <- mean(abs(PREDICTIONS - HP.TOTAL.IMPUTE.ENC.TRAIN.3$SalePrice)/HP.TOTAL.IMPUTE.ENC.TRAIN.3$SalePrice)
  {
    k = 10
    set.seed(1007)
    HP.TOTAL.IMPUTE.ENC.TRAIN$ID <- sample(1:k, nrow(HP.TOTAL.IMPUTE.ENC.TRAIN), replace = T)
    error        <- numeric()
    #Run XGBoost
    for (i in 1:k) {
      TRAIN <- HP.TOTAL.IMPUTE.ENC.TRAIN[HP.TOTAL.IMPUTE.ENC.TRAIN$ID != i,][,!(colnames(HP.TOTAL.IMPUTE.ENC.TRAIN) == "ID")]
      TEST  <- HP.TOTAL.IMPUTE.ENC.TRAIN[HP.TOTAL.IMPUTE.ENC.TRAIN$ID == i,][,!(colnames(HP.TOTAL.IMPUTE.ENC.TRAIN) == "ID")]
      set.seed(1007)
      XGB_K <- xgboost(data = data.matrix(TRAIN[,!(colnames(TRAIN) == "SalePrice")]),
                       label = TRAIN$SalePrice,
                       eta = 0.01,
                       max_depth = 3,
                       nround = 2000,
                       seed = 1007,
                       objective = "reg:linear",
                       nthread = 3,
                       verbose = F)
      #Predict prices on the test data
      PREDICTIONS <- predict(XGB_K, data.matrix(TEST[,!(colnames(TEST) == "SalePrice")]))
      RMSE        <- sqrt(mean((PREDICTIONS - TEST$SalePrice)^2))
      MAPE        <- mean(abs(PREDICTIONS - TEST$SalePrice)/TEST$SalePrice)
      print(paste0("Iteration : ",i," RMSE : ",round(RMSE,2)," MAPE :",round(MAPE,4)))
      error[i] <- MAPE
    }
    mean_MAPE <- mean(error)
    var_MAPE  <- var(error)
    print(paste0("Mape Mean : ",mean_MAPE,"Mape Variance : ",var_MAPE))
  }#k - fold validation
  {
    # [1] "Iteration : 1 RMSE : 24815.73 MAPE :0.0918"
    # [1] "Iteration : 2 RMSE : 37513.4 MAPE :0.0951"
    # [1] "Iteration : 3 RMSE : 20192.36 MAPE :0.0855"
    # [1] "Iteration : 4 RMSE : 27539.08 MAPE :0.1034"
    # [1] "Iteration : 5 RMSE : 25754.75 MAPE :0.0797"
    # [1] "Iteration : 6 RMSE : 26975.5 MAPE :0.0944"
    # [1] "Iteration : 7 RMSE : 42673.56 MAPE :0.1074"
    # [1] "Iteration : 8 RMSE : 22478.96 MAPE :0.0759"
    # [1] "Iteration : 9 RMSE : 30266.52 MAPE :0.0972"
    # [1] "Iteration : 10 RMSE : 22727.11 MAPE :0.0903"
    # [1] "Mape Mean - 0.0920777304886837Mape Variance - 9.64794842597865e-05"
  }#Results
  
  #Kaggle submission - 
  PREDICTIONS <- predict(XGB_K, data.matrix(HP.TOTAL.IMPUTE.ENC.TEST))
  submission  <- cbind(test$Id, PREDICTIONS)
  colnames(submission)   <- c("Id", "SalePrice")
  write.csv(submission, "170728_HP_ITER3.csv", row.names = F)  
  #Rank - 1106, score - 0.14354
  
  #Dimensionality reduction
  #Variable importance plots
  NAMES = dimnames(data.matrix(HP.TOTAL.IMPUTE.ENC.TRAIN.3[,!(colnames(HP.TOTAL.IMPUTE.ENC.TRAIN.3) %in% c("ID","SalePrice"))]))[[2]]
  IMPORTANCE.MATRIX <- xgb.importance(NAMES, XGB_1)
  xgb.plot.importance(IMPORTANCE.MATRIX)
  #View(IMPORTANCE.MATRIX)
  IMPORTANCE.MATRIX$Cumulativeimportance <- cumsum(IMPORTANCE.MATRIX$Importance)
  IMPORTANT_COLS <- IMPORTANCE.MATRIX$Feature[IMPORTANCE.MATRIX$Cumulativeimportance <= 0.99]
  #Filter train data to include important columns only
  HP.TOTAL.IMPUTE.ENC.TRAIN <- HP.TOTAL.IMPUTE.ENC.TRAIN[, (colnames(HP.TOTAL.IMPUTE.ENC.TRAIN) %in% c("Id", "SalePrice") |
                                                              colnames(HP.TOTAL.IMPUTE.ENC.TRAIN) %in% IMPORTANT_COLS)]
  #Run k - fold
  {
    # [1] "Iteration : 1 RMSE : 24156.57 MAPE :0.0941"
    # [1] "Iteration : 2 RMSE : 38015.3 MAPE :0.0953"
    # [1] "Iteration : 3 RMSE : 20293 MAPE :0.0857"
    # [1] "Iteration : 4 RMSE : 27819.78 MAPE :0.1006"
    # [1] "Iteration : 5 RMSE : 26140.36 MAPE :0.0842"
    # [1] "Iteration : 6 RMSE : 26749.81 MAPE :0.0952"
    # [1] "Iteration : 7 RMSE : 39662.84 MAPE :0.107"
    # [1] "Iteration : 8 RMSE : 22718.63 MAPE :0.0746"
    # [1] "Iteration : 9 RMSE : 32091.84 MAPE :0.1034"
    # [1] "Iteration : 10 RMSE : 22389.62 MAPE :0.0931"
    # [1] "Mape Mean - 0.0933141651543844Mape Variance - 9.36939581821811e-05"
  }#Results
  
  #Kaggle submission
  HP.TOTAL.IMPUTE.ENC.TEST <- HP.TOTAL.IMPUTE.ENC.TEST[, colnames(HP.TOTAL.IMPUTE.ENC.TEST) %in% IMPORTANT_COLS]
  PREDICTIONS <- predict(XGB_K, data.matrix(HP.TOTAL.IMPUTE.ENC.TEST))
  submission  <- cbind(test$Id, PREDICTIONS)
  colnames(submission)   <- c("Id", "SalePrice")
  write.csv(submission, "170802_HP_ITER6.csv", row.names = F)  
  #Rank - 1085, score - 0.14166
  
  #ITER5 & ITER6 : POST HYPERTUNING
  {
    # max_depth = 5
    # nround = 2000
    # [1] "Iteration : 1 RMSE : 24447.37 MAPE :0.0882"
    # [1] "Iteration : 2 RMSE : 37202.36 MAPE :0.0941"
    # [1] "Iteration : 3 RMSE : 19639.95 MAPE :0.0835"
    # [1] "Iteration : 4 RMSE : 27586.63 MAPE :0.1015"
    # [1] "Iteration : 5 RMSE : 25439.13 MAPE :0.0783"
    # [1] "Iteration : 6 RMSE : 27098.71 MAPE :0.0939"
    # [1] "Iteration : 7 RMSE : 42621.54 MAPE :0.1046"
    # [1] "Iteration : 8 RMSE : 21860.38 MAPE :0.0725"
    # [1] "Iteration : 9 RMSE : 30142.59 MAPE :0.0981"
    # [1] "Iteration : 10 RMSE : 22181.74 MAPE :0.0873"
    # [1] "Mape Mean - 0.0902096715778628Mape Variance - 0.000104226211124394"
    
    # For imprtant variables only
    # [1] "Iteration : 1 RMSE : 23865.85 MAPE :0.0926"
    # [1] "Iteration : 2 RMSE : 36693.86 MAPE :0.0912"
    # [1] "Iteration : 3 RMSE : 19529.62 MAPE :0.0832"
    # [1] "Iteration : 4 RMSE : 27257.78 MAPE :0.101"
    # [1] "Iteration : 5 RMSE : 24664.5 MAPE :0.0806"
    # [1] "Iteration : 6 RMSE : 27475.55 MAPE :0.0947"
    # [1] "Iteration : 7 RMSE : 40202.67 MAPE :0.1028"
    # [1] "Iteration : 8 RMSE : 22229.28 MAPE :0.0712"
    # [1] "Iteration : 9 RMSE : 31728.74 MAPE :0.0999"
    # [1] "Iteration : 10 RMSE : 22750.27 MAPE :0.0925"
    # [1] "Mape Mean - 0.0909662114671549Mape Variance - 9.94689592106002e-05"
    
    #Model overfitting on validation sets??
  }
    
}#07. Modelling technique - XGBoost
{
  
}#08. Feature engineering
