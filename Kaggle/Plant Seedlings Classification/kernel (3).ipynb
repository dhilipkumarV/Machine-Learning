{
  "cells": [
    {
      "metadata": {
        "_uuid": "9e3edb9eeeaf88b8c59d80b1ddf952e52c3f6d30"
      },
      "cell_type": "markdown",
      "source": "<h2> Reference </h2>\n* [Read images into python environment using OpenCV](https://docs.opencv.org/3.4.0/da/d6e/tutorial_py_geometric_transformations.html)\n*  [Create a virtual environment for running python in local](https://stackoverflow.com/questions/32167418/python-pip-install-trouble-shooting-permissionerror-winerror-5-access-is)\n    "
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom keras.applications import xception\nfrom keras.preprocessing import image\nimport keras.preprocessing.image\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport sklearn.ensemble\nimport numpy as np\nimport pandas as pd\nimport datetime as dt\nfrom tqdm import tqdm\nfrom glob import glob\nimport cv2\nimport os\nimport seaborn as sns\nimport mpl_toolkits.axes_grid1\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport datetime\n\n%matplotlib inline \nplt.rcParams['figure.figsize'] = [16,10]\nplt.rcParams['font.size'] = 16\n\n#start timer\nglobal_start = datetime.datetime.now();\n\n#validation set size\nvalid_set_size_percentage = 10; # default = 10%\n\n#kaggle\nrunning_on_kaggle = True # set True when running on kaggle environment\n\n#train data\ntake_only_samples_of_train_data = True; #set False to train on all train data\nnum_samples_of_train_data_per_species = 200 # < 221, ignored if take_only_samples_of_train_data = True\nload_bf_of_train_data = False # set True to load bottleneck features from file\n\n#test data\ntake_only_samples_of_test_data = False; # set False to predict on all test data\nnum_samples_of_test_data = 200 # < 794, ignored if take_only_samples_of_test_data = True\nload_bf_of_test_data = False # set True to load bottleneck features from file\n\n#augmented imagess\nuse_aug_data = False # set False to reduce notebook runtime\nload_bf_of_aug_data = True # set True to load bottleneck features from file\n\n#show plots\nshow_plots = True # set False to reduct notebook running time\n\n#overview of directories\nprint('current directory : ')\n!ls\nprint('\\nparent directory : ')\n!ls ..",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "72660cd9a8027a308d7256180c1970b756eed543"
      },
      "cell_type": "markdown",
      "source": "<h2>2.  Analyze Data</h2>\n\n* 12 different plan species\n* at least 211 images per species ==> 4750 images in training set\n* image sizes vary stringly ==> resize images to (299,299,3) for Xception input"
    },
    {
      "metadata": {
        "_uuid": "f5d7bab93c2c10864da7249ade3bcc376c7267c8",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# input directory\nprint('input directory : ')\n!ls ../input\nprint('\\nfolders containing images of corresponding species')\n!ls ../input/train/",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "_uuid": "08d32510bcf4e106ba52ba2e125824157190ccd1",
        "trusted": false
      },
      "cell_type": "code",
      "source": "# read train and test data\n\n# directiories\ncw_dir = os.getcwd()\ndata_dir = '../input/'\ntrain_dir = os.path.join(data_dir, 'train')\ntest_dir  = os.path.join(data_dir, 'test')\n\n# different species in the data set\nspecies = ['Black-grass',\n          'Common Chickweed',\n          'Loose Silky-bent',\n          'Shepherds Purse',\n          'Charlock',\n          'Common wheat',\n          'Maize',\n          'Small-flowered Cranesbill',\n          'Cleavers',\n          'Fat Hen',\n          'Scentless Mayweed',\n          'Sugar beet']\nnum_species = len(species)\n\n# print number of images of each species in the training data\nfor sp in species:\n    print('{} images of {}'.format(len(os.listdir(os.path.join(train_dir,sp))), sp))\n\n# read all train data\ntrain = []\nfor species_id, sp in enumerate(species):\n    #print(species_id, sp)\n    for file in os.listdir(os.path.join(train_dir, sp)):\n        train.append(['train/{}/{}'.format(sp, file), file, species_id, sp])\ntrain_df = pd.DataFrame(train, columns=['filepath',\n                                       'file',\n                                       'species_id',\n                                       'species'])\nprint('\\ntrain_df.shape = ', train_df.shape)\n\n# read all test data\ntest = []\nfor file in os.listdir(test_dir):\n    test.append(['test/{}'.format(file), file])\ntest_df  = pd.DataFrame(test, columns = ['filepath','file'])\nprint('test_df.shape = ', test_df.shape)\n\n# function to read an image \ndef read_img(filepath, target_size=None):\n    img = cv2.imread(os.path.join(data_dir, filepath), cv2.IMREAD_COLOR)\n    img = cv2.resize(img.copy(), target_size, interpolation = cv2.INTER_AREA)\n    #img = image.load_img(os.path.join(data_dir, filepath),target_size=target_size)\n    #img = image.img_to_array(img)\n    return img",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0747f5779cc1306a9b067da181418e113586fbaf",
        "trusted": false
      },
      "cell_type": "code",
      "source": "## get all image shapes: this is time-consuming, therefore I have deactivated\n## the code. The results are included below and show that all\n## images are quadratic, but their size can be very different. \n\nif True:\n    train_df['image_heigth'] = 0\n    train_df['image_width'] = 0\n    train_df['image_channel'] = 0\n\n    #get all image shapes\n    for i in range(len(train_df)):\n        img = read_img(train_df.filepath.values[i])\n        train_df.loc[i,'image_heigth'] = img.shape[0]\n        train_df.loc[i,'image_width'] = img.shape[1]\n        train_df.loc[i,'image_channel'] = img.shape[2]\n\n    test_df['image_heigth'] = 0\n    test_df['image_width'] = 0\n    test_df['image_channel'] = 0\n\n    # get all image shapes\n    for i in range(len(test_df)):\n        img = read_img(test_df.filepath.values[i])\n        test_df.loc[i,'image_heigth'] = img.shape[0]\n        test_df.loc[i,'image_width'] = img.shape[1]\n        test_df.loc[i,'image_channel'] = img.shape[2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f83eb21d9ea451fda6e647b5a1971c50b6745d52"
      },
      "cell_type": "markdown",
      "source": "<h3>Debug error with OpenCV</h3>\n\n[/io/opencv/modules/imgproc/src/resize.cpp:4045: error: (-215) dsize.area() > 0 || (inv_scale_x > 0 && inv_scale_y > 0) in function resize\n](https://stackoverflow.com/questions/31996367/opencv-resize-fails-on-large-image-with-error-215-ssize-area-0-in-funct)"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}